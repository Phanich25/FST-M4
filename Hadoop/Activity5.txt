root@7444154d5952:/# vi EmpData.csv
ID,Name,Department,JoinDate,Salary
1,Ian,Quality Assurance,2021,28113
2,Beatrice,Tech Support,2021,35330
3,Vladimir,Human Resources,2020,51445
4,Whitney,IT,2020,23818
5,Leslie,Customer Service,2021,59882
6,Bernard,IT,2021,50330
7,Mary,Customer Service,2021,26558
8,Jerome,RnD,2021,45333
9,Joshua,IT,2021,59538
10,Keane,Human Resources,2022,46500
11,Velma,Human Resources,2022,19816
12,Rogan,Tech Support,2022,27554
13,Aurelia,RnD,2021,20762
14,Merrill,Quality Assurance,2021,59660
15,Blaine,Tech Support,2022,28768

root@7444154d5952:/# hive
hive> create database office;
OK
Time taken: 0.107 seconds

hive> use office;
OK
Time taken: 0.023 seconds

hive> CREATE TABLE employee
    > (id INT, name STRING, dept STRING, yoj INT, salary INT)
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    > TBLPROPERTIES ("skip.header.line.count"="1");
OK
Time taken: 0.155 seconds

hive> describe employee;
OK
id                      int
name                    string
dept                    string
yoj                     int
salary                  int
Time taken: 0.045 seconds, Fetched: 5 row(s)

hive> LOAD DATA LOCAL INPATH
    > '/EmpData.csv'
    > INTO TABLE employee;
Loading data to table office.employee
OK
Time taken: 0.291 seconds

hive> select * from employee;
OK
1       Ian     Quality Assurance       2021    28113
2       Beatrice        Tech Support    2021    35330
3       Vladimir        Human Resources 2020    51445
4       Whitney IT      2020    23818
5       Leslie  Customer Service        2021    59882
6       Bernard IT      2021    50330
7       Mary    Customer Service        2021    26558
8       Jerome  RnD     2021    45333
9       Joshua  IT      2021    59538
10      Keane   Human Resources 2022    46500
11      Velma   Human Resources 2022    19816
12      Rogan   Tech Support    2022    27554
13      Aurelia RnD     2021    20762
14      Merrill Quality Assurance       2021    59660
15      Blaine  Tech Support    2022    28768
Time taken: 0.111 seconds, Fetched: 15 row(s)

hive> select count(*) from employee;
Query ID = root_20221210071922_97d20872-1f7f-4e24-ab38-9d7eef3dfb9e
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1670651172108_0006, Tracking URL = http://7444154d5952:8088/proxy/application_1670651172108_0006/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1670651172108_0006
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2022-12-10 07:19:29,600 Stage-1 map = 0%,  reduce = 0%
2022-12-10 07:19:35,814 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.0 sec
2022-12-10 07:19:40,944 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.58 sec
MapReduce Total cumulative CPU time: 5 seconds 580 msec
Ended Job = job_1670651172108_0006
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.58 sec   HDFS Read: 13162 HDFS Write: 102 SUCCESS
Total MapReduce CPU Time Spent: 5 seconds 580 msec
OK
15
Time taken: 19.526 seconds, Fetched: 1 row(s)

hive> select id,name from employee;
OK
1       Ian
2       Beatrice
3       Vladimir
4       Whitney
5       Leslie
6       Bernard
7       Mary
8       Jerome
9       Joshua
10      Keane
11      Velma
12      Rogan
13      Aurelia
14      Merrill
15      Blaine
Time taken: 0.101 seconds, Fetched: 15 row(s)

hive> select * from employee where salary > 30000;
OK
2       Beatrice        Tech Support    2021    35330
3       Vladimir        Human Resources 2020    51445
5       Leslie  Customer Service        2021    59882
6       Bernard IT      2021    50330
8       Jerome  RnD     2021    45333
9       Joshua  IT      2021    59538
10      Keane   Human Resources 2022    46500
14      Merrill Quality Assurance       2021    59660
Time taken: 0.144 seconds, Fetched: 8 row(s)

hive> select count(*) from employee;
Query ID = root_20221210072218_d7fd487a-bf43-46f0-af4f-7254851a04d5
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1670651172108_0007, Tracking URL = http://7444154d5952:8088/proxy/application_1670651172108_0007/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1670651172108_0007
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2022-12-10 07:22:25,853 Stage-1 map = 0%,  reduce = 0%
2022-12-10 07:22:29,976 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.56 sec
2022-12-10 07:22:36,125 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.6 sec
MapReduce Total cumulative CPU time: 5 seconds 600 msec
Ended Job = job_1670651172108_0007
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.6 sec   HDFS Read: 13162 HDFS Write: 102 SUCCESS
Total MapReduce CPU Time Spent: 5 seconds 600 msec
OK
15
Time taken: 19.335 seconds, Fetched: 1 row(s)

hive> dfs -ls /user/phani/output/;
Found 2 items
-rw-r--r--   1 root supergroup        480 2022-11-18 07:44 /user/phani/output/000000_0
drwxr-xr-x   - root supergroup          0 2022-12-10 07:24 /user/phani/output/result

hive> dfs -mkdir /user/phani/output/export;

hive> dfs -ls /user/phani/output/export;
hive>

hive> INSERT OVERWRITE DIRECTORY '/user/phani/output/export'
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    > SELECT * FROM office.employee;
Query ID = root_20221210072759_65ea75e4-9d42-4297-b808-ec1520b13b4b
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1670651172108_0008, Tracking URL = http://7444154d5952:8088/proxy/application_1670651172108_0008/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1670651172108_0008
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
2022-12-10 07:28:06,735 Stage-1 map = 0%,  reduce = 0%
2022-12-10 07:28:11,883 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.38 sec
MapReduce Total cumulative CPU time: 3 seconds 380 msec
Ended Job = job_1670651172108_0008
Stage-3 is selected by condition resolver.
Stage-2 is filtered out by condition resolver.
Stage-4 is filtered out by condition resolver.
Moving data to directory hdfs://7444154d5952:9000/user/phani/output/export/.hive-staging_hive_2022-12-10_07-27-59_699_7845081232829829942-1/-ext-10000
Moving data to directory /user/phani/output/export
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1   Cumulative CPU: 3.38 sec   HDFS Read: 5573 HDFS Write: 480 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 380 msec
OK
Time taken: 14.323 seconds

hive> dfs -ls /user/phani/output/export;
Found 1 items
-rw-r--r--   1 root supergroup        480 2022-12-10 07:28 /user/phani/output/export/000000_0

hive> INSERT OVERWRITE LOCAL DIRECTORY '/export'
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    > SELECT * FROM office.employee;
Query ID = root_20221210073101_79b3a7dc-57b1-4093-9907-cfb816cb915a
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1670651172108_0009, Tracking URL = http://7444154d5952:8088/proxy/application_1670651172108_0009/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1670651172108_0009
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
2022-12-10 07:31:08,227 Stage-1 map = 0%,  reduce = 0%
2022-12-10 07:31:13,381 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.65 sec
MapReduce Total cumulative CPU time: 2 seconds 650 msec
Ended Job = job_1670651172108_0009
Moving data to local directory /export
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1   Cumulative CPU: 2.65 sec   HDFS Read: 5658 HDFS Write: 480 SUCCESS
Total MapReduce CPU Time Spent: 2 seconds 650 msec
OK
Time taken: 13.353 seconds

root@7444154d5952:/# ls /export
000000_0